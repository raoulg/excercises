{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import fashion_mnist, mnist\n",
    "import datetime\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input, Dropout, BatchNormalization\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This week, no asserts. Just make sure you have a clean notebook, that runs without errors. Show that you can explore the dataset, starting with a basemodel, trying things to improve upon the baseline. You will submit the complete notebook, and I will grade the complete notebook. I will grade the notebook on things like:\n",
    "\n",
    "- clean code\n",
    "- small comments or cells with markdown, explaining what you are doing (just like you would do for a colleague that has to read your code)\n",
    "- Improving the performance. Near 90% should be doable with a bit of effort."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data\n",
    "The MNIST sort of became too easy. We get levels close to 99%, so it get's increasingly harder to see what improves or not. So we want a set that is harder. The fashion_mnist is a bit harder, but still doable with relative easy techniques. We can still train on a default laptop, while it is hard enough to have some space for tweaking and improving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_valid, y_valid) = fashion_mnist.load_data()\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_valid, y_valid, test_size=0.4, random_state=42)\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore the set a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(X_train[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[y_train[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline\n",
    "Build a baseline deep learning model with settings you guess are simple, but good enough to give you a baseline to improve. E.g. try just one or two layers of Dense layers.\n",
    "\n",
    "Store results and scores.\n",
    "\n",
    "If you are curious about simple (non-deep learning models) You can have a look here [here](http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/#) for benchmarks with simple models. Note the trainingtime, before you attempt to reproduce this with a simple model; some really take hours! Also try to sort the models by accuracy, and note the best model: an SVC with a kernel... Downside is, that it takes more than an hour to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {}\n",
    "score = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout, Batchnorm, activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment manually with batchnorm, drops and different activations to get a sense of how they impact the model. \n",
    "Store your results in dictionaries, such that is it easy to compare (see lesson for examples). If you want to test with `Conv2D` and `MaxPool2D` layers, you can use `Reshape((28,28,1))` to get the desired 4D shape for image convolutions.\n",
    "\n",
    "Getting above 90% on the testset is actually pretty good for the fashion mnist.\n",
    " \n",
    "**USE SEEDS**: that way, I can reproduce your results. And warn me for cells that take a long time to run, e.g. by putting the expected runtime in a comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scores(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save your best manual tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('manual_tune.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypertuning\n",
    "Build a hypermodel. Start with broad settings, and use `hp.Fixed` to fixate things your are fairly sure about. You should be able to get above 90% accuracy on the testset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kerastuner as kt\n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_epochs=5, # increasing the amount of epochs will increase the amount of trials\n",
    "    factor=3, # decreasing the factor will increase the amount of trials\n",
    "    seed=10, # by setting the seed, you guarantee the same outcome every time you run the hyperband\n",
    "    hyperband_iterations=1, # run the complete algorithm more than once, starting from scratch every time.\n",
    "    directory='ktuner',\n",
    "    project_name='fashion_mnist'\n",
    ")\n",
    "tuner.search(X_train, y_train, validation_data = (X_valid, y_valid), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(num_trials = 1)[0]\n",
    "print(best_hps.values)\n",
    "model = tuner.get_best_models()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "result['hyper'] = model.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid), callbacks=[early_stop], verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score['hyper']=model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scores(score, ymin=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('hypertune.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('hypertune.h5')\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
